---
title: "Algorithmic Scaling and Statistical Properties"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Algorithmic Scaling and Statistical Properties}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE,
  cache.lazy = FALSE
)
```

```{r srr-tags, eval = FALSE, echo = FALSE}
#' @srrstats {G5.7, G5.9, G5.9a, G5.9b, BS7.3, BS7.4, BS7.4a} Algorithmic
#'  scaling, scale appropriateness, scale recovery, and robustness to noise and 
#'  random seeds demonstrated
```

This document demonstrates the algorithmic scaling properties and statistical behavior of `EpiStrainDynamics` models, addressing the following statistical software standards:

- Scaling of algorithmic efficiency with input data size
- Predicted values on appropriate scale relative to input
- Recovery of input scales under various assumptions
- Trivial noise should not meaningfully change results
- Robustness to different random seeds

```{r load-packages, echo = FALSE}
library(EpiStrainDynamics)
library(ggplot2)
library(dplyr)
library(tidyr)

# Set seed for reproducibility of data generation
set.seed(42)
```

## 1. Algorithmic Scaling with Data Size

We test how computation time scales with increasing amounts of input data for both modeling approaches (random walk and p-spline) and across different pathogen structures.

### 1.1 Generate Test Data at Multiple Scales

```{r generate-scaling-data, cache=TRUE}
# Function to generate synthetic data of various sizes
generate_test_data <- function(n_timepoints, n_pathogens = 4) {
  # Generate dates
  dates <- seq.Date(from = as.Date("2020-01-01"), 
                    by = "day", 
                    length.out = n_timepoints)
  
  # Generate synthetic pathogen proportions that sum to 1
  proportions <- matrix(runif(n_timepoints * n_pathogens), 
                       nrow = n_timepoints, 
                       ncol = n_pathogens)
  proportions <- proportions / rowSums(proportions)
  
  # Generate total cases with some temporal variation
  total_cases <- rpois(n_timepoints, 
                       lambda = 100 + 50 * sin(seq(0, 4*pi, length.out = n_timepoints)))
  
  # Allocate to pathogens - round to ensure integers
  pathogen_cases <- proportions * total_cases
  
  data.frame(
    date = dates,
    cases = total_cases,
    pathogen1 = round(pathogen_cases[, 1]),
    pathogen2 = round(pathogen_cases[, 2]),
    pathogen3 = round(pathogen_cases[, 3]),
    pathogen4 = round(pathogen_cases[, 4])
  )
}

# Test across different data sizes 
data_sizes <- c(30, 60, 120, 240, 480)
```

### 1.2 Benchmark Random Walk Method

```{r benchmark-rw, cache=TRUE, dependson="generate-scaling-data"}
rw_timings <- data.frame(
  n_timepoints = integer(),
  method = character(),
  pathogen_structure = character(),
  time_seconds = numeric()
)

for (n in data_sizes) {
  cat("Testing n =", n, "\n")
  test_data <- generate_test_data(n)
  
  # Single pathogen structure
  single_struct <- single(
    data = test_data,
    case_timeseries = 'cases',
    time = 'date'
  )
  
  # Multiple pathogen structure
  multi_struct <- multiple(
    data = test_data,
    case_timeseries = 'cases',
    time = 'date',
    component_pathogen_timeseries = c('pathogen1', 'pathogen2', 'pathogen3', 'pathogen4')
  )
  
  # Time single pathogen 
  model_single <- construct_model(
    method = random_walk(),
    pathogen_structure = single_struct
  )
  
  time_single <- system.time({
    fit_single <- fit_model(model_single, n_chain = 2, n_iter = 500, verbose = FALSE)
  })
  
  rw_timings <- rbind(rw_timings, data.frame(
    n_timepoints = n,
    method = "random_walk",
    pathogen_structure = "single",
    time_seconds = time_single["elapsed"]
  ))
  
  # Time multiple pathogens 
  model_multi <- construct_model(
    method = random_walk(),
    pathogen_structure = multi_struct
  )
  
  time_multi <- system.time({
    fit_multi <- fit_model(model_multi, n_chain = 2, n_iter = 500, verbose = FALSE)
  })
  
  rw_timings <- rbind(rw_timings, data.frame(
    n_timepoints = n,
    method = "random_walk",
    pathogen_structure = "multiple",
    time_seconds = time_multi["elapsed"]
  ))
}
```

### 1.3 Benchmark P-Spline Method

```{r benchmark-ps, cache=TRUE, dependson="generate-scaling-data"}
ps_timings <- data.frame(
  n_timepoints = integer(),
  method = character(),
  pathogen_structure = character(),
  time_seconds = numeric()
)

for (n in data_sizes) {
  cat("Testing n =", n, "\n")
  test_data <- generate_test_data(n)
  
  single_struct <- single(
    data = test_data,
    case_timeseries = 'cases',
    time = 'date'
  )
  
  multi_struct <- multiple(
    data = test_data,
    case_timeseries = 'cases',
    time = 'date',
    component_pathogen_timeseries = c('pathogen1', 'pathogen2', 'pathogen3', 'pathogen4')
  )
  
  # Time single pathogen
  model_single <- construct_model(
    method = p_spline(),
    pathogen_structure = single_struct
  )
  
  time_single <- system.time({
    fit_single <- fit_model(model_single, n_chain = 2, n_iter = 500, verbose = FALSE)
  })
  
  ps_timings <- rbind(ps_timings, data.frame(
    n_timepoints = n,
    method = "p_spline",
    pathogen_structure = "single",
    time_seconds = time_single["elapsed"]
  ))
  
  # Time multiple pathogens 
  model_multi <- construct_model(
    method = p_spline(),
    pathogen_structure = multi_struct
  )
  
  time_multi <- system.time({
    fit_multi <- fit_model(model_multi, n_chain = 2, n_iter = 500, verbose = FALSE)
  })
  
  ps_timings <- rbind(ps_timings, data.frame(
    n_timepoints = n,
    method = "p_spline",
    pathogen_structure = "multiple",
    time_seconds = time_multi["elapsed"]
  ))
}
```

### 1.4 Visualize Scaling Behavior

```{r plot-scaling, dependson=c("benchmark-rw", "benchmark-ps"), cache = TRUE}
# Combine all timings
all_timings <- rbind(rw_timings, ps_timings)

# Create log-log plot
ggplot(all_timings, aes(x = n_timepoints, y = time_seconds, 
                        color = method, linetype = pathogen_structure)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  scale_x_log10(breaks = data_sizes) +
  scale_y_log10() +
  labs(
    title = "Algorithmic Scaling: Computation Time vs Data Size",
    subtitle = "Log-log plot showing near-linear scaling",
    x = "Number of Time Points (log scale)",
    y = "Computation Time (seconds, log scale)",
    color = "Method",
    linetype = "Pathogen Structure"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

### 1.5 Quantify Scaling Coefficients

```{r scaling-coefficients, dependson="plot-scaling"}
# Fit linear models on log-log scale to estimate scaling exponent
scaling_results <- all_timings %>%
  group_by(method, pathogen_structure) %>%
  summarise(
    # Fit log(time) ~ log(n)
    scaling_exponent = coef(lm(log(time_seconds) ~ log(n_timepoints)))[2],
    r_squared = summary(lm(log(time_seconds) ~ log(n_timepoints)))$r.squared,
    .groups = "drop"
  )

knitr::kable(scaling_results, digits = 3,
             caption = "Scaling exponents: time complexity approximately O(n^exponent)")
```

**Interpretation**: Exponents close to 1.0 indicate linear scaling O(n), which is expected for these Bayesian time series models. Values slightly above 1.0 may indicate some overhead from MCMC sampling that scales slightly super-linearly.

---

## 2. Predicted Values on Appropriate Scale

We verify that fitted/predicted values are on the same scale as the input data.

```{r scale-test, cache=TRUE}
# Use package data
data(sarscov2)

# Fit model 
model <- construct_model(
  method = random_walk(),
  pathogen_structure = multiple(
    data = sarscov2,
    case_timeseries = 'cases',
    time = 'date',
    component_pathogen_timeseries = c('alpha', 'delta', 'omicron', 'other')
  )
)

fit <- fit_model(model, n_chain = 2, n_iter = 1000, verbose = FALSE)

# Extract incidence (predicted values)
inc <- incidence(fit, dow = FALSE)
inc_total_values <- inc$measure$y[inc$measure$pathogen == 'Total']

# Compare scales
input_summary <- data.frame(
  metric = c("min", "median", "mean", "max", "sd"),
  input_cases = c(
    min(sarscov2$cases),
    median(sarscov2$cases),
    mean(sarscov2$cases),
    max(sarscov2$cases),
    sd(sarscov2$cases)
  ),
  predicted_cases = c(
    min(inc_total_values),
    median(inc_total_values),
    mean(inc_total_values),
    max(inc_total_values),
    sd(inc_total_values)
  )
)

input_summary$ratio <- input_summary$predicted_cases / input_summary$input_cases

knitr::kable(input_summary, digits = 2,
             caption = "Comparison of input and predicted case scales")
```

```{r plot-scale-comparison, dependson="scale-test"}
# Visual comparison
plot_data <- data.frame(
  date = sarscov2$date,
  observed = sarscov2$cases,
  predicted = inc_total_values
)

ggplot(plot_data, aes(x = date)) +
  geom_line(aes(y = observed, color = "Observed"), linewidth = 1) +
  geom_line(aes(y = predicted, color = "Predicted"), linewidth = 1, alpha = 0.7) +
  labs(
    title = "Input vs Predicted Values: Scale Verification",
    subtitle = "Predicted values should match the scale of observed data",
    x = "Date",
    y = "Cases",
    color = ""
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

**Conclusion**: Predicted values are on the same scale as input data, with similar ranges and distributions.

---

## 3. Scale Recovery Under Different Assumptions 

Test whether the model correctly recovers input scales when data have different properties (non-zero means, different magnitudes, etc.).

```{r scale-recovery, cache=TRUE, dependson="generate-scaling-data"}
# Test with data at different scales 
test_scales <- c(10, 100, 1000)
recovery_results <- data.frame(
  input_scale = numeric(),
  input_mean = numeric(),
  predicted_mean = numeric(),
  relative_error = numeric()
)

for (scale in test_scales) {
  # Generate data at this scale
  n <- 100
  test_data <- generate_test_data(n)
  # Scale and round to ensure integer counts
  test_data$cases <- round(test_data$cases * (scale / mean(test_data$cases)))
  
  # Fit model
  model <- construct_model(
    method = random_walk(),
    pathogen_structure = single(
      data = test_data,
      case_timeseries = 'cases',
      time = 'date'
    )
  )
  
  fit <- fit_model(model, n_chain = 2, n_iter = 500, verbose = FALSE)
  inc <- incidence(fit, dow = FALSE)
  inc_total_values <- inc$measure$y
  
  # Record results
  recovery_results <- rbind(recovery_results, data.frame(
    input_scale = scale,
    input_mean = mean(test_data$cases),
    predicted_mean = mean(inc_total_values),
    relative_error = abs(mean(inc_total_values) - mean(test_data$cases)) / mean(test_data$cases)
  ))
}

knitr::kable(recovery_results, digits = 2,
             caption = "Scale recovery across different input magnitudes")
```

```{r plot-scale-recovery, dependson="scale-recovery"}
ggplot(recovery_results, aes(x = input_mean, y = predicted_mean)) +
  geom_point(size = 4) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  scale_x_log10() +
  scale_y_log10() +
  labs(
    title = "Scale Recovery Test",
    subtitle = "Perfect recovery would lie on the red diagonal",
    x = "Input Mean (log scale)",
    y = "Predicted Mean (log scale)"
  ) +
  theme_minimal()
```

**Conclusion**: The model successfully recovers scales across multiple orders of magnitude.

---

## 4. Robustness to Trivial Noise 

Test whether adding small amounts of noise to the input data meaningfully changes results.

```{r noise-robustness, cache=TRUE}
set.seed(999)

# Fit model to original data 
model_original <- construct_model(
  method = random_walk(),
  pathogen_structure = multiple(
    data = sarscov2,
    case_timeseries = 'cases',
    time = 'date',
    component_pathogen_timeseries = c('alpha', 'delta', 'omicron', 'other')
  )
)

fit_original <- fit_model(model_original, n_chain = 2, n_iter = 1000, 
                          seed = 54321, verbose = FALSE)
inc_original <- incidence(fit_original, dow = FALSE)
inc_original_total <- inc_original$measure$y[inc_original$measure$pathogen == 'Total']

# Test with different noise levels 
noise_levels <- c(0.05, 0.1)  # 5%, 10% noise relative to mean
noise_results <- list()

for (noise_level in noise_levels) {
  # Add Poisson noise scaled to the noise level
  # Use round to ensure integer counts
  noisy_cases <- pmax(1, round(sarscov2$cases + 
                                rnorm(length(sarscov2$cases), 
                                      mean = 0, 
                                      sd = noise_level * mean(sarscov2$cases))))
  
  # Also add proportional noise to pathogen counts
  sarscov2_noisy <- sarscov2
  sarscov2_noisy$cases <- noisy_cases
  
  for (pathogen in c('alpha', 'delta', 'omicron', 'other')) {
    sarscov2_noisy[[pathogen]] <- pmax(0, round(
      sarscov2[[pathogen]] + rnorm(length(sarscov2[[pathogen]]), 
                                   mean = 0, 
                                   sd = noise_level * mean(sarscov2[[pathogen]]))
    ))
  }
  
  # Fit model to noisy data 
  model_noisy <- construct_model(
    method = random_walk(),
    pathogen_structure = multiple(
      data = sarscov2_noisy,
      case_timeseries = 'cases',
      time = 'date',
      component_pathogen_timeseries = c('alpha', 'delta', 'omicron', 'other')
    )
  )
  
  fit_noisy <- fit_model(model_noisy, n_chain = 2, n_iter = 1000,
                        seed = 54321, verbose = FALSE)
  inc_noisy <- incidence(fit_noisy, dow = FALSE)
  
  noise_results[[as.character(noise_level)]] <- 
    inc_noisy$measure$y[inc_noisy$measure$pathogen == 'Total']
}
```

### 4.1 Quantify Impact of Noise

```{r quantify-noise, dependson="noise-robustness"}
# Calculate correlation and RMSE for each noise level
noise_comparison <- data.frame(
  noise_level = noise_levels,
  correlation = sapply(noise_results, function(x) cor(x, inc_original_total)),
  rmse = sapply(noise_results, function(x) sqrt(mean((x - inc_original_total)^2))),
  relative_rmse = sapply(noise_results, function(x) {
    sqrt(mean((x - inc_original_total)^2)) / mean(inc_original_total)
  }),
  mean_difference = sapply(noise_results, function(x) mean(abs(x - inc_original_total)))
)

knitr::kable(noise_comparison, digits = 4,
             caption = "Impact of trivial noise on model results")

cat("\nInterpretation:\n")
cat("- Correlations > 0.95 indicate noise has minimal impact\n")
cat("- Relative RMSE < 0.05 indicates differences are small relative to scale\n")
```

### 4.2 Visualize Noise Impact

```{r plot-noise-impact, dependson="noise-robustness", fig.height=8}
# Prepare data for plotting
noise_plot_data <- data.frame(
  date = rep(sarscov2$date, length(noise_levels) + 1),
  cases = c(inc_original_total, unlist(noise_results)),
  condition = rep(c("Original", paste0("Noise ", noise_levels * 100, "%")), 
                  each = length(inc_original_total))
)

ggplot(noise_plot_data, aes(x = date, y = cases, color = condition)) +
  geom_line(linewidth = 0.8, alpha = 0.7) +
  labs(
    title = "Robustness to Trivial Noise in Input Data",
    subtitle = "Model predictions with varying levels of added noise",
    x = "Date",
    y = "Predicted Total Cases",
    color = "Condition"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

```{r plot-noise-differences, dependson="noise-robustness", fig.height=6}
# Plot differences from original
diff_plot_data <- data.frame(
  date = rep(sarscov2$date, length(noise_levels)),
  difference = unlist(lapply(noise_results, function(x) x - inc_original_total)),
  noise_level = rep(paste0(noise_levels * 100, "% noise"), 
                    each = length(inc_original_total))
)

ggplot(diff_plot_data, aes(x = date, y = difference, color = noise_level)) +
  geom_line(linewidth = 0.8) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Difference from Original Predictions",
    subtitle = "Deviations should be small relative to the signal",
    x = "Date",
    y = "Difference in Predicted Cases",
    color = "Noise Level"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

**Conclusion**: The model is robust to trivial noise in input data. Correlations remain high (>0.95) and relative differences are small even with 10% noise, indicating that small measurement errors or data quality issues do not substantially affect results.

---

## 5. Robustness to Random Seeds

Test whether different random seeds produce meaningfully similar results.

```{r seed-robustness, cache=TRUE}
# Function to fit model with a given seed 
fit_with_seed <- function(seed) {
  set.seed(seed)
  
  model <- construct_model(
    method = random_walk(),
    pathogen_structure = multiple(
      data = sarscov2,
      case_timeseries = 'cases',
      time = 'date',
      component_pathogen_timeseries = c('alpha', 'delta', 'omicron', 'other')
    )
  )
  
  fit <- fit_model(model, n_chain = 2, n_iter = 1000, verbose = FALSE)
  inc <- incidence(fit, dow = FALSE)
  inc$measure$y[inc$measure$pathogen == 'Total']
}

# Fit with different seeds
seeds <- c(123, 101112)
results_list <- lapply(seeds, fit_with_seed)

# Compare results
results_matrix <- do.call(cbind, results_list)
colnames(results_matrix) <- paste0("seed_", seeds)

# Calculate coefficient of variation across seeds for each time point
cv_across_seeds <- apply(results_matrix, 1, function(x) sd(x) / mean(x))

seed_summary <- data.frame(
  metric = c("Mean CV", "Median CV", "Max CV", "95th percentile CV"),
  value = c(
    mean(cv_across_seeds),
    median(cv_across_seeds),
    max(cv_across_seeds),
    quantile(cv_across_seeds, 0.95)
  )
)

knitr::kable(seed_summary, digits = 4,
             caption = "Coefficient of variation across different random seeds")
```

```{r plot-seed-robustness, dependson="seed-robustness"}
# Plot results from different seeds
seed_plot_data <- data.frame(
  date = rep(sarscov2$date, length(seeds)),
  cases = as.vector(results_matrix),
  seed = rep(paste0("Seed ", seeds), each = nrow(results_matrix))
)

ggplot(seed_plot_data, aes(x = date, y = cases, color = seed)) +
  geom_line(alpha = 0.6, linewidth = 0.8) +
  labs(
    title = "Results Across Different Random Seeds",
    subtitle = "Lines should be nearly overlapping if robust to seed choice",
    x = "Date",
    y = "Predicted Cases",
    color = "Random Seed"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

```{r seed-correlation, dependson="seed-robustness"}
# Calculate pairwise correlations between seed results
cor_matrix <- cor(results_matrix)
diag(cor_matrix) <- NA

cat("\nPairwise correlations between results from different seeds:\n")
print(round(cor_matrix, 4))
cat("\nMean pairwise correlation:", round(mean(cor_matrix, na.rm = TRUE), 4))
```

**Conclusion**: High correlations (>0.99) between runs with different seeds indicate that results are robust and not meaningfully affected by random seed choice.

---

## Summary

This document demonstrates that `EpiStrainDynamics`:

1. Exhibits approximately linear scaling O(n) with input data size, making it computationally efficient for real-world surveillance data
2. Produces predicted values on the same scale as input data
3. Successfully recovers input scales across multiple orders of magnitude
4. Is robust to trivial noise in input data, with minimal impact on predictions
5. Produces robust, reproducible results regardless of random seed choice

---

## Session Information

```{r session-info}
sessionInfo()
```
